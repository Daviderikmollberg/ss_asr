import torch
import torch.nn as nn

class Discriminator(nn.Module):
    def __init__(self, in_dim:int, hidden_dim:int=256):
        '''
        Input arguments:
        in_dim (int): The feature dimension of samples supplied as inputs
        to the discriminator
        hidden_dim (int): Number of nodes per layer in the discriminator

        In our model, the discriminator is a simple feed-forward
        network with two fully-connected layers. It takes as input
        a single vector, and outputs a single real-valued score in the
        interval [0, 1]. 
        The discriminator is trained using binary cross-
        entropy loss to assign high scores to output vectors generated
        by the text encoder and low scores to those generated by the
        speech encoder. We use label smoothing
        
        My interpretation is then that the Discriminator 
        'evaluates' each time step of its input, rather than 
        emitting a 0 or 1 per utterance.
        
        Direct quote from Drexler:
        It takes as input a single vector, and outputs a single 
        real-valued score in the interval [0, 1]. The discriminator 
        is trained using binary cross-entropy loss to assign high scores 
        to output vectors generated by the text encoder and low scores 
        to those generated by the speech encoder.

        Reasoning: 
        * Listener output (Generator): [batch_size, ~seq/8, 512]
        * Text encoder output (Data distribution): [batch_size. seq, 512]
        '''
        super(Discriminator, self).__init__()

        self.core = nn.Sequential(
            torch.nn.Linear(in_dim, hidden_dim),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_dim, hidden_dim),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_dim, 1))
    
    def forward(self, x):
        '''
        A [batch_size, seq, 512] tensor, containing all frames from 
        each batch from either the Text Encoder or Listener.

        '''
        out = self.core(x)
        # apply the sigmoid function to get outputs in the (0,1) range
        # this is needed to use the _Binary_ cross entropy loss function
        out = torch.sigmoid(out)
        return out